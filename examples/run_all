#!/bin/bash -e
#
# Run two different backends, with different architectures
#
# * D-PLDA: PLDA form trained discriminatively
#
# * DCA-PLDA: duration and sideinfo dependent DPLDA: same as above
#   with the addition of a calibration stage that depends on an
#   automatically extracted side-info vector and the duration of the
#   samples.
#
# Results from this script can be found in the following files
#
# output/train*/*/seed*/stage*/eval_best/all_results
#
# The results include counts, EER, Cllr and DCF metrics. Cllr and DCF
# are computed with two different ptar values. Also, we compute the
# actual value as well as the min value for each case. The min values
# for the Cllr metrics are computed in two different ways: by doing a
# cheating linear logistic regression on the test data itself (the
# ones called "LIN") and by using the PAV algorithm on the test data
# (called "PAV"). The PAV estimates are slightly lower since that
# model is non-parametric and can adapt more to the test data, which
# might result in overfitting.
#
# Training is run in two stages, to allow for different training
# parameters in each stage.  The model from the first iteration in
# stage 1 correspond to a standard a PLDA backend.
#
# Results from this script show that:
#
# * Simple Discriminative PLDA gives better results than PLDA
#
# * When training only with vox data, perfomance on vox-like sets
#   (voxceleb2 and sitw) is very good for all three models, with
#   DCA-PLDA outperforming the other two by a small margin
#
# * When training with vox and fvcaus data, performance of PLDA on
#   vox-like data degrades significantly. On the other hand,
#   performance with DCA-PLDA on vox-like sets is almost as good as
#   when training with vox only, while giving large gains on fvcaus
#   heldout data.
#
# Hence, DCA-PLDA allows us to use heterogeous data to train a single
# SID system that gives excellent performance for all conditions
# considered in training. As shown in our papers, when trained on a
# larger variety of data, this model can also generalize to unseen
# conditions.


# CPU or GPU number, if GPU is available
device=1
seed=0

# Sets used to choose the best model from the second stage
dev_sets="heldout_vox heldout_vox_4-30sec" 

printf "%-30s %-15s %-15s %-15s %-15s\n" "Set" "Train-Data" "System" "Min-Cllr" "Actual-Cllr" > tmp$$

for trndata in vox vox+fvcaus; do

    out_dir=output/train_${trndata}
    
    for archn in dplda dplda_dursidep; do

	conf=configs/arch/$archn.ini
	./run_expt -d "$dev_sets" -o $out_dir/$archn/seed$seed -a $conf -D $device -s $seed -t $trndata

    done

    # For full results with all metrics, look at the files below:
    plda=$out_dir/dplda/seed$seed/stage1/eval_ep0000/all_results
    dplda=$out_dir/dplda/seed$seed/stage2/eval_best/all_results
    dcaplda=$out_dir/dplda_dursidep/seed$seed/stage2/eval_best/all_results
    
    # Summarized results showing only actual Cllr and grouped by set rather than my model for ease of comparison
    cat $plda    | gawk -v t=$trndata -v n=1.PLDA    'NR>2{gsub(/:.*/,"",$1); printf "%-30s %-15s %-15s %-15s %-15s\n", $1, t, n, $9, $8}' >> tmp$$
    cat $dplda   | gawk -v t=$trndata -v n=2.DPLDA   'NR>2{gsub(/:.*/,"",$1); printf "%-30s %-15s %-15s %-15s %-15s\n", $1, t, n, $9, $8}' >> tmp$$
    cat $dcaplda | gawk -v t=$trndata -v n=3.DCAPLDA 'NR>2{gsub(/:.*/,"",$1); printf "%-30s %-15s %-15s %-15s %-15s\n", $1, t, n, $9, $8}' >> tmp$$
done

cat tmp$$ | sort | gawk '{if($1!=prev) print ""; prev=$1; print}'
rm tmp$$


